# -*- coding: utf-8 -*-
"""aivsreal.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xzJptXPTdcQt2Ktskrv_cGKTsxphvyJb
"""

import os
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from keras.utils import to_categorical
from tensorflow.keras.utils import load_img
from keras.models import Sequential
from keras.applications import MobileNetV2, ResNet152, VGG16, EfficientNetB0, InceptionV3
from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D
from sklearn.preprocessing import LabelEncoder
from tqdm.notebook import tqdm
from tensorflow.keras.callbacks import EarlyStopping

from PIL import Image
from IPython.display import display

!pip install pillow
!pip install webptools
import webptools

from google.colab import drive
drive.mount('/content/drive')

def createdataframe(dir):
    image_paths=[]
    labels=[]
    for label in os.listdir(dir):
#os.listdir(dir) returns a list containing the names of the entries in the directory given by dir.
      for imagename in os.listdir(os.path.join(dir,label)):
         image_path = os.path.join(dir, label, imagename)
         if os.path.isfile(image_path):
          image_paths.append(os.path.join(dir,label,imagename)) #OR tf.keras.utils.image_dataset_from_directory('directory_name')
          labels.append(label)
      print(label,"completed")
    return image_paths,labels

def extract_features(images):
  features=[]
  valid_image_paths=[]
  for image_path in tqdm(images):
    try:
      if( image_path.lower().endswith('.webp')):
        jpeg_path = image_path.replace('.webp', '.jpg')
        webptools.dwebp(input_image=image_path, output_image=jpeg_path, option="-o", logging="-v")
                # Load and process the converted JPEG image
        img = load_img(jpeg_path, target_size=(128, 128))
                # Remove temporary JPEG file
        #os.remove(jpeg_path)
     #img=Image.open(image_path)
        #if img.format not in ['JPEG', 'PNG', 'GIF', 'BMP', 'JPG', 'jpg']:  # Add other supported formats if needed
       # print(f"Warning: Unsupported image format '{img.format}' for image: {image_path}")
        #continue """
      else:
        img=load_img(image_path,target_size=(128,128))
        img=np.array(img)
        features.append(img)
    except (IOError, OSError) as e:
            print(f"Warning: Skipping image '{image_path}' due to error: {e}")
            continue


  features=np.array(features)
  features=features.reshape(features.shape[0],128,128,3)
  return features

TRAIN_DIR="/content/drive/MyDrive/New_Data"
train=pd.DataFrame()
train['image'],train['label']=createdataframe(TRAIN_DIR)
train_features=extract_features(train['image'])
x_train=train_features/255.0 #to scale pixel values(ranging from 0 to 255) from 0 to 1
os.listdir(TRAIN_DIR)

le=LabelEncoder()
le.fit(train['label'])
y_train=le.transform(train['label'])
y_train=to_categorical(y_train,num_classes=2) # to_categorical by keras converts class vector into binary class matrix
print(le.classes_)

early_stopping= EarlyStopping(
    monitor='accuracy',
    mode='max',
    patience=5,
    restore_best_weights=True
)

model=Sequential()
model.add(Conv2D(32,(3,3),1,activation='relu',input_shape=(128,128,3)))
model.add(BatchNormalization())
model.add(MaxPooling2D())

model.add(Conv2D(256, (3,3), 1, activation='relu'))
model.add(BatchNormalization())
model.add(MaxPooling2D())

model.add(Conv2D(512, (3,3), 1, activation='relu'))
model.add(BatchNormalization())
model.add(MaxPooling2D())

model.add(Flatten())

model.add(Dense(1024,activation='relu'))
model.add(BatchNormalization())
model.add(Dropout(0.2))
model.add(Dense(512,activation='relu'))
model.add(Dropout(0.3))
model.add(Dense(256,activation='relu'))
model.add(Dense(128,activation='relu'))
model.add(Dense(2,activation='sigmoid')) #sigmoid instead of softmax

model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])

model.summary()
"""if x_train.shape[0] == 0 or y_train.shape[0] == 0:
    raise ValueError("Training data is empty. Please check your data loading process.")"""

batch_size=16
if batch_size > x_train.shape[0]:
    batch_size = 8 # Set batch size to the number of samples if it's larger
    print(f"Warning: Batch size is larger than the number of training samples. ")
model.fit(x=x_train,y=y_train,batch_size=batch_size,epochs=15)

test_image_dir='/content/drive/MyDrive/Test_Images'
import imghdr

def create_test_dataframe(dir):
    image_paths = []
    image_names = []
    for filename in os.listdir(dir):
      file_path = os.path.join(dir, filename)
      if imghdr.what(file_path) is not None:
        #if filename.endswith('.jpg'):
         image_paths.append(file_path)
         image_names.append(filename)

    return image_paths,image_names

label_mapping = {0: 'AI', 1: 'Real'}

test=pd.DataFrame()
test['image'],test['image_name']=create_test_dataframe(test_image_dir)
print(test['image_name'])
test_features=extract_features(test['image'])
x_test=test_features/255.0

predictions=model.predict(x_test)
predicted_labels=np.argmax(predictions,axis=1)

results=pd.DataFrame({'Id': test['image_name'], 'label':predicted_labels})
results['label']=results['label'].map(label_mapping)
results.to_csv('predictions3.csv',header=True, index=False)