This repository contains the implementation for Task 1: AI vs REAL and GAN implementation as part of the Cynaptics Inductions program.  
## AI vs REAL image classification
This project implements a convolutional neural network (CNN) to classify images as either "AI-generated" or "Real".
it involves 
-Data Loading and Preprocessing
-Model Definition and Training
-Prediction and Output

A sequential CNN with convolutional, pooling, batch normalization, and dense layers. Trained with Adam optimizer and binary cross-entropy loss.
The `createdataframe` function assumes a directory structure where subdirectories represent labels.
The `extract_features` function includes error handling for invalid image files and converts `.webp` images.

## Setup

1.  Install dependencies
2.  Organize training images by label in subdirectories (e.g., `Train/AI/`, `Train/Real/`).
3.  Place test images in a separate directory.
4.  Update `TRAIN_DIR` and `test_image_dir` in the notebook.
5.  Run the notebook.

## output 
`predictions3.csv` containing image names and predicted labels ("AI" or "Real")

## Generative Adversarial Network Implementation
A GAN consists of two main components:

1.  **Generator:** This network learns to create synthetic data (in this case, images) that resemble the training data.
2.  **Discriminator:** This network learns to distinguish between real data from the training set and fake data generated by the generator.

During training, the generator and discriminator are trained in an adversarial manner. The generator tries to produce data that can fool the discriminator, while the discriminator tries to get better at identifying fake data. This process continues until the generator is capable of producing realistic-looking data.

## Project Structure

*   Data loading and preprocessing for the MNIST dataset.
*   Definition of the Generator and Discriminator neural network architectures.
*   Loss functions and optimizers for training.
*   A training loop to train the GAN.
*   Functions to visualize generated images.


 **Imports:** Necessary libraries
*   **Visualization Function (`show`):** A helper function to display a grid of generated images using `torchvision.utils.make_grid`.
*   **Hyperparameters:** Definition of key parameters like `epoch`, `z_dim`, `lr`, `batch_size`, `device`, `info_iter`.
*   **Data Loading:** Uses `torchvision.datasets.MNIST` and `torch.utils.data.DataLoader` to load and batch the MNIST data with `transforms.ToTensor()`.
*   **Generator Architecture (`genBlock`, `Generator`):**
    *   `genBlock`: A helper function to create a sequential block for the generator, including `nn.Linear`, `nn.BatchNorm1d`, and `nn.ReLU`.
    *   `Generator`: The main class defining the generator network, which is a `nn.Module` containing a `nn.Sequential` of `genBlock`s and a final `nn.Linear` layer with `nn.Sigmoid` activation.
*   **Discriminator Architecture (`discblock`, `Discriminator`):**
    *   `discblock`: A helper function to create a sequential block for the discriminator, including `nn.Linear`, `nn.LeakyReLU(0.2)`, and `nn.Dropout(0.2)`.
    *   `Discriminator`: The main class defining the discriminator network, which is a `nn.Module` containing a `nn.Sequential` of `discblock`s and a final `nn.Linear` layer.
*   **Optimizers:** Uses `torch.optim.RMSprop` with specified learning rates (`lr`) for both the generator (`gen_opt`) and discriminator (`disc_opt`).
*   **Loss Function:** Uses `nn.BCEWithLogitsLoss()` as the criterion (`loss`) for both generator and discriminator losses.
*   **Loss Calculation Functions (`gen_loss`, `disc_loss`):**
*   **Training Loop:** The main `for` loop iterates through `epoch`s and uses `tqdm` for progress tracking. Inside the loop:
    *   It iterates through the `dataloader` to get batches of real images.
    *   It calculates and backpropagates the discriminator loss using `disc_loss`.
    *   It calculates and backpropagates the generator loss using `gen_loss`.
    *   It updates the model weights using `disc_opt.step()` and `gen_opt.step()`.
    *   It tracks mean losses (`mean_disc_loss`, `mean_gen_loss`) and prints progress along with generated images using `show` every `info_iter` iterations.

## SETUP 
Follow these steps to set up and run the project:

1.  **Clone the Repository:**
2.  **Install Dependencies:**
    Navigate into the cloned repository directory. Install the required Python libraries using pip:

3.  **Run in Google Colab:**
    This code is designed to be run in a Google Colab environment.
    *   Go to [Google Colab](https://colab.research.google.com/).
    *   Click on "File" -> "Upload notebook" and select the `.ipynb` file from your cloned repository.
    *   Once the notebook is loaded, you can run the cells sequentially or choose "Runtime" -> "Run all".


